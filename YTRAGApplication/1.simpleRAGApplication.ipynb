{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "nG6m3Q9DBHV1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33R54QYjCMAJ"
      },
      "source": [
        "## Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "hPcswe0tExci"
      },
      "outputs": [],
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZZrs-ijCTYt"
      },
      "source": [
        "## Step 1a - Indexing (Document Ingestion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1p9AXZycFIH6",
        "outputId": "74950ea5-66f9-4242-bf72-7b2d2ba3aaa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "If you're building AI agents, you've probably heard about MCP or Model Context Protocol. MCP is a new open source standard to connect your agents to data sources such as databases or APIs. MCP consists of multiple components. The most important ones are the host, the client, and the server. So let's break it down. At the very top you would have your MCP host. Your MCP host will include an MCP client. And it could also include multiple clients. The MCP host could be an application such as a chat app. It could also be a code assistant in your IDE, and much more. The MCP host will connect to an MCP server. It can actually connect to multiple MCP servers as well. It doesn't matter how many MCP servers you connect to your MCP host or client. The MCP host and servers will connect over each other through the MCP protocol. The MCP protocol is a transport layer in the middle. Whenever your MCP host or client needs a tool, it's going to connect to the MCP server. The MCP server will then connect to, for example, a database. And it doesn't matter if this is a relational database or a NoSQL database. It could also connect to APIs. And also the API standard doesn't really matter. Finally, it could also connect to data sources such as a local file type or maybe code. This is especially useful when you're building something like a code assistant in your IDE. Let's look at an example of how to use MCP in practice. We still have the three components. We would have our MCP host and client, of course, we also have a large language model, and finally, we have our MCP servers, and these could be multiple MCP servers or just a single one. Let's assume our MCP client and host is a chat app, and you ask a question such as, what is the weather like in a certain location or how many customers do I have? The MCP host will need to retrieve tools from the MCP server. The MCP server will then conclude and tell which tools are available. From the MCP host, you would then have to connect to the large language model and send over your question plus the available tools. If all is well, the LLM will reply and tell you which tools to use. Once the MCP host and client knows which tools to use, it knows which MCP servers to call. So when it calls the MCP server in order to get a tool result, the MCP server will be responsible for executing something that goes to a database, to an API, or a local piece of code, and of course, there could be subsequent calls to MCP servers. The MCP server will apply with a response, which you can send back to the LLM. And finally, you should be able to get your final answer based on the question that you asked in the chat application. If you are building agents, I'd really advise you to look at MCP protocol. The MCP protocol is a new standard which will help you to connect your data sources via MCP server to any agent. Even though you might not be building agents, your client might be building agents. And if you enjoyed this video, make sure to like and subscribe.\n"
          ]
        }
      ],
      "source": [
        "video_id = \"eur8dUO9mvE\" # only the ID, not full URL\n",
        "try:\n",
        "    # If you don’t care which language, this returns the “best” one\n",
        "    transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=[\"en\"])\n",
        "\n",
        "    # Flatten it to plain text\n",
        "    transcript = \" \".join(chunk[\"text\"] for chunk in transcript_list)\n",
        "    print(transcript)\n",
        "\n",
        "except TranscriptsDisabled:\n",
        "    print(\"No captions available for this video.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWSK4-VQH8CG",
        "outputId": "01528517-4192-4620-f234-97055e4b6655"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'text': \"If you're building AI agents, you've probably heard about MCP or Model Context Protocol.\",\n",
              "  'start': 0.4,\n",
              "  'duration': 4.299},\n",
              " {'text': 'MCP is a new open source standard to connect your agents to data sources such as databases or APIs.',\n",
              "  'start': 5.24,\n",
              "  'duration': 5.699},\n",
              " {'text': 'MCP consists of multiple components.',\n",
              "  'start': 11.68,\n",
              "  'duration': 1.919},\n",
              " {'text': 'The most important ones are the host, the client, and the server.',\n",
              "  'start': 13.94,\n",
              "  'duration': 3.08},\n",
              " {'text': \"So let's break it down.\", 'start': 17.22, 'duration': 1.0},\n",
              " {'text': 'At the very top you would have your MCP host.',\n",
              "  'start': 19.53,\n",
              "  'duration': 2.459},\n",
              " {'text': 'Your MCP host will include an MCP client.',\n",
              "  'start': 22.57,\n",
              "  'duration': 2.8},\n",
              " {'text': 'And it could also include multiple clients.',\n",
              "  'start': 25.91,\n",
              "  'duration': 1.9},\n",
              " {'text': 'The MCP host could be an application such as a chat app.',\n",
              "  'start': 28.37,\n",
              "  'duration': 4.039},\n",
              " {'text': 'It could also be a code assistant in your IDE, and much more.',\n",
              "  'start': 33.63,\n",
              "  'duration': 4.08},\n",
              " {'text': 'The MCP host will connect to an MCP server.',\n",
              "  'start': 38.52,\n",
              "  'duration': 2.5},\n",
              " {'text': 'It can actually connect to multiple MCP servers as well.',\n",
              "  'start': 41.6,\n",
              "  'duration': 2.68},\n",
              " {'text': \"It doesn't matter how many MCP servers you connect to your MCP host or client.\",\n",
              "  'start': 48.8,\n",
              "  'duration': 3.44},\n",
              " {'text': 'The MCP host and servers will connect over each other through the MCP protocol.',\n",
              "  'start': 53.19,\n",
              "  'duration': 4.44},\n",
              " {'text': 'The MCP protocol is a transport layer in the middle.',\n",
              "  'start': 57.63,\n",
              "  'duration': 3.099},\n",
              " {'text': \"Whenever your MCP host or client needs a tool, it's going to connect to the MCP server.\",\n",
              "  'start': 64.93,\n",
              "  'duration': 4.08},\n",
              " {'text': 'The MCP server will then connect to, for example, a database.',\n",
              "  'start': 69.29,\n",
              "  'duration': 3.079},\n",
              " {'text': \"And it doesn't matter if this is a relational database or a NoSQL database.\",\n",
              "  'start': 72.91,\n",
              "  'duration': 3.7},\n",
              " {'text': 'It could also connect to APIs.', 'start': 77.07, 'duration': 1.62},\n",
              " {'text': \"And also the API standard doesn't really matter.\",\n",
              "  'start': 80.5,\n",
              "  'duration': 2.239},\n",
              " {'text': 'Finally, it could also connect to data sources such as a local file type or maybe code.',\n",
              "  'start': 83.12,\n",
              "  'duration': 5.459},\n",
              " {'text': \"This is especially useful when you're building something like a code assistant in your IDE.\",\n",
              "  'start': 90.59,\n",
              "  'duration': 4.899},\n",
              " {'text': \"Let's look at an example of how to use MCP in practice.\",\n",
              "  'start': 96.58,\n",
              "  'duration': 2.68},\n",
              " {'text': 'We still have the three components.',\n",
              "  'start': 100.12,\n",
              "  'duration': 1.339},\n",
              " {'text': 'We would have our MCP host and client,',\n",
              "  'start': 101.6,\n",
              "  'duration': 2.64},\n",
              " {'text': 'of course, we also have a large language model,',\n",
              "  'start': 106.02,\n",
              "  'duration': 2.56},\n",
              " {'text': 'and finally, we have our MCP servers,',\n",
              "  'start': 113.17,\n",
              "  'duration': 2.38},\n",
              " {'text': 'and these could be multiple MCP servers or just a single one.',\n",
              "  'start': 116.03,\n",
              "  'duration': 3.4},\n",
              " {'text': \"Let's assume our MCP client and host is a chat app,\",\n",
              "  'start': 123.43,\n",
              "  'duration': 2.9},\n",
              " {'text': 'and you ask a question such as, what is the weather like in a certain location or how many customers do I have?',\n",
              "  'start': 127.023,\n",
              "  'duration': 5.667},\n",
              " {'text': 'The MCP host will need to retrieve tools from the MCP server.',\n",
              "  'start': 133.29,\n",
              "  'duration': 3.659},\n",
              " {'text': 'The MCP server will then conclude and tell which tools are available.',\n",
              "  'start': 138.72,\n",
              "  'duration': 3.54},\n",
              " {'text': 'From the MCP host, you would then have to connect to the large language model',\n",
              "  'start': 143.32,\n",
              "  'duration': 3.313},\n",
              " {'text': 'and send over your question plus the available tools.',\n",
              "  'start': 146.633,\n",
              "  'duration': 2.927},\n",
              " {'text': 'If all is well, the LLM will reply and tell you which tools to use.',\n",
              "  'start': 150.96,\n",
              "  'duration': 3.84},\n",
              " {'text': 'Once the MCP host and client knows which tools to use, it knows which MCP servers to call.',\n",
              "  'start': 158.28,\n",
              "  'duration': 4.839},\n",
              " {'text': 'So when it calls the MCP server in order to get a tool result,',\n",
              "  'start': 163.6,\n",
              "  'duration': 4.607},\n",
              " {'text': 'the MCP server will be responsible for executing something that goes to a database, to an API, or a local piece of code,',\n",
              "  'start': 168.846,\n",
              "  'duration': 8.984},\n",
              " {'text': 'and of course, there could be subsequent calls to MCP servers.',\n",
              "  'start': 179.07,\n",
              "  'duration': 2.98},\n",
              " {'text': 'The MCP server will apply with a response, which you can send back to the LLM.',\n",
              "  'start': 182.89,\n",
              "  'duration': 4.839},\n",
              " {'text': 'And finally, you should be able to get your final answer based on the question that you asked in the chat application.',\n",
              "  'start': 187.85,\n",
              "  'duration': 5.679},\n",
              " {'text': \"If you are building agents, I'd really advise you to look at MCP protocol.\",\n",
              "  'start': 195.06,\n",
              "  'duration': 3.52},\n",
              " {'text': 'The MCP protocol is a new standard which will help you to connect your data sources via MCP server to any agent.',\n",
              "  'start': 198.8,\n",
              "  'duration': 5.98},\n",
              " {'text': 'Even though you might not be building agents, your client might be building agents.',\n",
              "  'start': 205.28,\n",
              "  'duration': 3.56},\n",
              " {'text': 'And if you enjoyed this video, make sure to like and subscribe.',\n",
              "  'start': 209.44,\n",
              "  'duration': 2.56}]"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transcript_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKkcYsaOCrRX"
      },
      "source": [
        "## Step 1b - Indexing (Text Splitting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "24i-ZSVXFbnC"
      },
      "outputs": [],
      "source": [
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "chunks = splitter.create_documents([transcript])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Dm9sfpQFnF1",
        "outputId": "7b9bea3d-b5a4-47f1-f793-16b6bfdd6a7b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYlrcBrkFO-N",
        "outputId": "b6e33df4-c8a2-4c2d-f929-4af59774bd94"
      },
      "outputs": [],
      "source": [
        "# chunks[100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xYFK7WXC2Ka"
      },
      "source": [
        "## Step 1c & 1d - Indexing (Embedding Generation and Storing in Vector Store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "jYXeS5T7FrC4"
      },
      "outputs": [],
      "source": [
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "vector_store = FAISS.from_documents(chunks, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWYkp-NmFSVF",
        "outputId": "36f75b4d-b798-4e06-aeea-5c56c91befe0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'ad45e536-2023-4db2-8886-a5cbcebc2aea',\n",
              " 1: '785175a3-6ca4-4759-ad13-3576c75d58e3',\n",
              " 2: 'ab4c2238-24c7-4d6a-8aa3-84e27123b40a',\n",
              " 3: 'd163f1a9-3291-409f-8e79-d5f3f844068e'}"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector_store.index_to_docstore_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxokTcWEGGAo",
        "outputId": "e05f7a2a-4cb1-4fb0-ba48-e6887877a260"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector_store.get_by_ids(['6879e71a-fad7-410a-a3fc-10293ff7998c'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zez1650EDN9J"
      },
      "source": [
        "## Step 2 - Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "KEuoGUYOF3oG"
      },
      "outputs": [],
      "source": [
        "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qcose8VuGFAv",
        "outputId": "f8e5472c-4073-4e44-af3a-f4ffcd023dc5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x00000208C18BBB10>, search_kwargs={'k': 4})"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wvrsq08TGGNk",
        "outputId": "55ed9475-4497-4e53-d380-5c4c10bf68cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='ad45e536-2023-4db2-8886-a5cbcebc2aea', metadata={}, page_content=\"If you're building AI agents, you've probably heard about MCP or Model Context Protocol. MCP is a new open source standard to connect your agents to data sources such as databases or APIs. MCP consists of multiple components. The most important ones are the host, the client, and the server. So let's break it down. At the very top you would have your MCP host. Your MCP host will include an MCP client. And it could also include multiple clients. The MCP host could be an application such as a chat app. It could also be a code assistant in your IDE, and much more. The MCP host will connect to an MCP server. It can actually connect to multiple MCP servers as well. It doesn't matter how many MCP servers you connect to your MCP host or client. The MCP host and servers will connect over each other through the MCP protocol. The MCP protocol is a transport layer in the middle. Whenever your MCP host or client needs a tool, it's going to connect to the MCP server. The MCP server will then connect\"),\n",
              " Document(id='785175a3-6ca4-4759-ad13-3576c75d58e3', metadata={}, page_content=\"through the MCP protocol. The MCP protocol is a transport layer in the middle. Whenever your MCP host or client needs a tool, it's going to connect to the MCP server. The MCP server will then connect to, for example, a database. And it doesn't matter if this is a relational database or a NoSQL database. It could also connect to APIs. And also the API standard doesn't really matter. Finally, it could also connect to data sources such as a local file type or maybe code. This is especially useful when you're building something like a code assistant in your IDE. Let's look at an example of how to use MCP in practice. We still have the three components. We would have our MCP host and client, of course, we also have a large language model, and finally, we have our MCP servers, and these could be multiple MCP servers or just a single one. Let's assume our MCP client and host is a chat app, and you ask a question such as, what is the weather like in a certain location or how many customers do\"),\n",
              " Document(id='ab4c2238-24c7-4d6a-8aa3-84e27123b40a', metadata={}, page_content=\"multiple MCP servers or just a single one. Let's assume our MCP client and host is a chat app, and you ask a question such as, what is the weather like in a certain location or how many customers do I have? The MCP host will need to retrieve tools from the MCP server. The MCP server will then conclude and tell which tools are available. From the MCP host, you would then have to connect to the large language model and send over your question plus the available tools. If all is well, the LLM will reply and tell you which tools to use. Once the MCP host and client knows which tools to use, it knows which MCP servers to call. So when it calls the MCP server in order to get a tool result, the MCP server will be responsible for executing something that goes to a database, to an API, or a local piece of code, and of course, there could be subsequent calls to MCP servers. The MCP server will apply with a response, which you can send back to the LLM. And finally, you should be able to get your\"),\n",
              " Document(id='d163f1a9-3291-409f-8e79-d5f3f844068e', metadata={}, page_content=\"of code, and of course, there could be subsequent calls to MCP servers. The MCP server will apply with a response, which you can send back to the LLM. And finally, you should be able to get your final answer based on the question that you asked in the chat application. If you are building agents, I'd really advise you to look at MCP protocol. The MCP protocol is a new standard which will help you to connect your data sources via MCP server to any agent. Even though you might not be building agents, your client might be building agents. And if you enjoyed this video, make sure to like and subscribe.\")]"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever.invoke('What is MCP?')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8y0wRmoDSVZ"
      },
      "source": [
        "## Step 3 - Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "x2P2AlJ0GN5L"
      },
      "outputs": [],
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "2-NeLx9wFHzw"
      },
      "outputs": [],
      "source": [
        "prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "      You are a helpful assistant.\n",
        "      Answer ONLY from the provided transcript context.\n",
        "      If the context is insufficient, just say you don't know.\n",
        "\n",
        "      {context}\n",
        "      Question: {question}\n",
        "    \"\"\",\n",
        "    input_variables = ['context', 'question']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "WI9BOZQwGizf"
      },
      "outputs": [],
      "source": [
        "question          = \"What is there in this particular video?\"\n",
        "retrieved_docs    = retriever.invoke(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfv8yNFsK_GN",
        "outputId": "79fa2a7e-8d92-45bf-99e4-ad12cd86c7a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='ab4c2238-24c7-4d6a-8aa3-84e27123b40a', metadata={}, page_content=\"multiple MCP servers or just a single one. Let's assume our MCP client and host is a chat app, and you ask a question such as, what is the weather like in a certain location or how many customers do I have? The MCP host will need to retrieve tools from the MCP server. The MCP server will then conclude and tell which tools are available. From the MCP host, you would then have to connect to the large language model and send over your question plus the available tools. If all is well, the LLM will reply and tell you which tools to use. Once the MCP host and client knows which tools to use, it knows which MCP servers to call. So when it calls the MCP server in order to get a tool result, the MCP server will be responsible for executing something that goes to a database, to an API, or a local piece of code, and of course, there could be subsequent calls to MCP servers. The MCP server will apply with a response, which you can send back to the LLM. And finally, you should be able to get your\"),\n",
              " Document(id='785175a3-6ca4-4759-ad13-3576c75d58e3', metadata={}, page_content=\"through the MCP protocol. The MCP protocol is a transport layer in the middle. Whenever your MCP host or client needs a tool, it's going to connect to the MCP server. The MCP server will then connect to, for example, a database. And it doesn't matter if this is a relational database or a NoSQL database. It could also connect to APIs. And also the API standard doesn't really matter. Finally, it could also connect to data sources such as a local file type or maybe code. This is especially useful when you're building something like a code assistant in your IDE. Let's look at an example of how to use MCP in practice. We still have the three components. We would have our MCP host and client, of course, we also have a large language model, and finally, we have our MCP servers, and these could be multiple MCP servers or just a single one. Let's assume our MCP client and host is a chat app, and you ask a question such as, what is the weather like in a certain location or how many customers do\"),\n",
              " Document(id='d163f1a9-3291-409f-8e79-d5f3f844068e', metadata={}, page_content=\"of code, and of course, there could be subsequent calls to MCP servers. The MCP server will apply with a response, which you can send back to the LLM. And finally, you should be able to get your final answer based on the question that you asked in the chat application. If you are building agents, I'd really advise you to look at MCP protocol. The MCP protocol is a new standard which will help you to connect your data sources via MCP server to any agent. Even though you might not be building agents, your client might be building agents. And if you enjoyed this video, make sure to like and subscribe.\"),\n",
              " Document(id='ad45e536-2023-4db2-8886-a5cbcebc2aea', metadata={}, page_content=\"If you're building AI agents, you've probably heard about MCP or Model Context Protocol. MCP is a new open source standard to connect your agents to data sources such as databases or APIs. MCP consists of multiple components. The most important ones are the host, the client, and the server. So let's break it down. At the very top you would have your MCP host. Your MCP host will include an MCP client. And it could also include multiple clients. The MCP host could be an application such as a chat app. It could also be a code assistant in your IDE, and much more. The MCP host will connect to an MCP server. It can actually connect to multiple MCP servers as well. It doesn't matter how many MCP servers you connect to your MCP host or client. The MCP host and servers will connect over each other through the MCP protocol. The MCP protocol is a transport layer in the middle. Whenever your MCP host or client needs a tool, it's going to connect to the MCP server. The MCP server will then connect\")]"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retrieved_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "bKwpvAo5G_Pk",
        "outputId": "26f0efd0-b35f-44dd-9735-dfc41c1ab86d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"multiple MCP servers or just a single one. Let's assume our MCP client and host is a chat app, and you ask a question such as, what is the weather like in a certain location or how many customers do I have? The MCP host will need to retrieve tools from the MCP server. The MCP server will then conclude and tell which tools are available. From the MCP host, you would then have to connect to the large language model and send over your question plus the available tools. If all is well, the LLM will reply and tell you which tools to use. Once the MCP host and client knows which tools to use, it knows which MCP servers to call. So when it calls the MCP server in order to get a tool result, the MCP server will be responsible for executing something that goes to a database, to an API, or a local piece of code, and of course, there could be subsequent calls to MCP servers. The MCP server will apply with a response, which you can send back to the LLM. And finally, you should be able to get your\\n\\nthrough the MCP protocol. The MCP protocol is a transport layer in the middle. Whenever your MCP host or client needs a tool, it's going to connect to the MCP server. The MCP server will then connect to, for example, a database. And it doesn't matter if this is a relational database or a NoSQL database. It could also connect to APIs. And also the API standard doesn't really matter. Finally, it could also connect to data sources such as a local file type or maybe code. This is especially useful when you're building something like a code assistant in your IDE. Let's look at an example of how to use MCP in practice. We still have the three components. We would have our MCP host and client, of course, we also have a large language model, and finally, we have our MCP servers, and these could be multiple MCP servers or just a single one. Let's assume our MCP client and host is a chat app, and you ask a question such as, what is the weather like in a certain location or how many customers do\\n\\nof code, and of course, there could be subsequent calls to MCP servers. The MCP server will apply with a response, which you can send back to the LLM. And finally, you should be able to get your final answer based on the question that you asked in the chat application. If you are building agents, I'd really advise you to look at MCP protocol. The MCP protocol is a new standard which will help you to connect your data sources via MCP server to any agent. Even though you might not be building agents, your client might be building agents. And if you enjoyed this video, make sure to like and subscribe.\\n\\nIf you're building AI agents, you've probably heard about MCP or Model Context Protocol. MCP is a new open source standard to connect your agents to data sources such as databases or APIs. MCP consists of multiple components. The most important ones are the host, the client, and the server. So let's break it down. At the very top you would have your MCP host. Your MCP host will include an MCP client. And it could also include multiple clients. The MCP host could be an application such as a chat app. It could also be a code assistant in your IDE, and much more. The MCP host will connect to an MCP server. It can actually connect to multiple MCP servers as well. It doesn't matter how many MCP servers you connect to your MCP host or client. The MCP host and servers will connect over each other through the MCP protocol. The MCP protocol is a transport layer in the middle. Whenever your MCP host or client needs a tool, it's going to connect to the MCP server. The MCP server will then connect\""
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
        "context_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "_bikWKZWDiqB"
      },
      "outputs": [],
      "source": [
        "final_prompt = prompt.invoke({\"context\": context_text, \"question\": question})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LOFVVAbLYvU",
        "outputId": "b6c47460-fdf3-4dad-ebe5-611b3dfe854b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "StringPromptValue(text=\"\\n      You are a helpful assistant.\\n      Answer ONLY from the provided transcript context.\\n      If the context is insufficient, just say you don't know.\\n\\n      multiple MCP servers or just a single one. Let's assume our MCP client and host is a chat app, and you ask a question such as, what is the weather like in a certain location or how many customers do I have? The MCP host will need to retrieve tools from the MCP server. The MCP server will then conclude and tell which tools are available. From the MCP host, you would then have to connect to the large language model and send over your question plus the available tools. If all is well, the LLM will reply and tell you which tools to use. Once the MCP host and client knows which tools to use, it knows which MCP servers to call. So when it calls the MCP server in order to get a tool result, the MCP server will be responsible for executing something that goes to a database, to an API, or a local piece of code, and of course, there could be subsequent calls to MCP servers. The MCP server will apply with a response, which you can send back to the LLM. And finally, you should be able to get your\\n\\nthrough the MCP protocol. The MCP protocol is a transport layer in the middle. Whenever your MCP host or client needs a tool, it's going to connect to the MCP server. The MCP server will then connect to, for example, a database. And it doesn't matter if this is a relational database or a NoSQL database. It could also connect to APIs. And also the API standard doesn't really matter. Finally, it could also connect to data sources such as a local file type or maybe code. This is especially useful when you're building something like a code assistant in your IDE. Let's look at an example of how to use MCP in practice. We still have the three components. We would have our MCP host and client, of course, we also have a large language model, and finally, we have our MCP servers, and these could be multiple MCP servers or just a single one. Let's assume our MCP client and host is a chat app, and you ask a question such as, what is the weather like in a certain location or how many customers do\\n\\nof code, and of course, there could be subsequent calls to MCP servers. The MCP server will apply with a response, which you can send back to the LLM. And finally, you should be able to get your final answer based on the question that you asked in the chat application. If you are building agents, I'd really advise you to look at MCP protocol. The MCP protocol is a new standard which will help you to connect your data sources via MCP server to any agent. Even though you might not be building agents, your client might be building agents. And if you enjoyed this video, make sure to like and subscribe.\\n\\nIf you're building AI agents, you've probably heard about MCP or Model Context Protocol. MCP is a new open source standard to connect your agents to data sources such as databases or APIs. MCP consists of multiple components. The most important ones are the host, the client, and the server. So let's break it down. At the very top you would have your MCP host. Your MCP host will include an MCP client. And it could also include multiple clients. The MCP host could be an application such as a chat app. It could also be a code assistant in your IDE, and much more. The MCP host will connect to an MCP server. It can actually connect to multiple MCP servers as well. It doesn't matter how many MCP servers you connect to your MCP host or client. The MCP host and servers will connect over each other through the MCP protocol. The MCP protocol is a transport layer in the middle. Whenever your MCP host or client needs a tool, it's going to connect to the MCP server. The MCP server will then connect\\n      Question: What is there in this particular video?\\n    \")"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxxcV2C_DXqt"
      },
      "source": [
        "## Step 4 - Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HX6vxSoUHBok",
        "outputId": "eade1e56-b8af-4b7e-c34b-08a4a1b0da00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This video describes the Model Context Protocol (MCP), a new open-source standard for connecting AI agents to data sources like databases or APIs.  It explains the three main components: the host, client, and server, and how they interact using the MCP protocol as a transport layer.  The video uses the example of a chat app to illustrate how MCP works in practice, showing how a question is routed through the system to access tools and retrieve information from various sources (databases, APIs, local code).  The video also advises viewers building AI agents to consider using the MCP protocol.\n"
          ]
        }
      ],
      "source": [
        "answer = llm.invoke(final_prompt)\n",
        "print(answer.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH2Ph0NcDlo5"
      },
      "source": [
        "## Building a Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "RdTwSS3nHKRz"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "VGezE1qYQJ76"
      },
      "outputs": [],
      "source": [
        "def format_docs(retrieved_docs):\n",
        "  context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
        "  return context_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "fmYnYqbWQWLi"
      },
      "outputs": [],
      "source": [
        "parallel_chain = RunnableParallel({\n",
        "    'context': retriever | RunnableLambda(format_docs),\n",
        "    'question': RunnablePassthrough()\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGI1hEvfQvLb",
        "outputId": "093b395c-69da-44d8-dbef-b313f3752687"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context': \"through the MCP protocol. The MCP protocol is a transport layer in the middle. Whenever your MCP host or client needs a tool, it's going to connect to the MCP server. The MCP server will then connect to, for example, a database. And it doesn't matter if this is a relational database or a NoSQL database. It could also connect to APIs. And also the API standard doesn't really matter. Finally, it could also connect to data sources such as a local file type or maybe code. This is especially useful when you're building something like a code assistant in your IDE. Let's look at an example of how to use MCP in practice. We still have the three components. We would have our MCP host and client, of course, we also have a large language model, and finally, we have our MCP servers, and these could be multiple MCP servers or just a single one. Let's assume our MCP client and host is a chat app, and you ask a question such as, what is the weather like in a certain location or how many customers do\\n\\nof code, and of course, there could be subsequent calls to MCP servers. The MCP server will apply with a response, which you can send back to the LLM. And finally, you should be able to get your final answer based on the question that you asked in the chat application. If you are building agents, I'd really advise you to look at MCP protocol. The MCP protocol is a new standard which will help you to connect your data sources via MCP server to any agent. Even though you might not be building agents, your client might be building agents. And if you enjoyed this video, make sure to like and subscribe.\\n\\nmultiple MCP servers or just a single one. Let's assume our MCP client and host is a chat app, and you ask a question such as, what is the weather like in a certain location or how many customers do I have? The MCP host will need to retrieve tools from the MCP server. The MCP server will then conclude and tell which tools are available. From the MCP host, you would then have to connect to the large language model and send over your question plus the available tools. If all is well, the LLM will reply and tell you which tools to use. Once the MCP host and client knows which tools to use, it knows which MCP servers to call. So when it calls the MCP server in order to get a tool result, the MCP server will be responsible for executing something that goes to a database, to an API, or a local piece of code, and of course, there could be subsequent calls to MCP servers. The MCP server will apply with a response, which you can send back to the LLM. And finally, you should be able to get your\\n\\nIf you're building AI agents, you've probably heard about MCP or Model Context Protocol. MCP is a new open source standard to connect your agents to data sources such as databases or APIs. MCP consists of multiple components. The most important ones are the host, the client, and the server. So let's break it down. At the very top you would have your MCP host. Your MCP host will include an MCP client. And it could also include multiple clients. The MCP host could be an application such as a chat app. It could also be a code assistant in your IDE, and much more. The MCP host will connect to an MCP server. It can actually connect to multiple MCP servers as well. It doesn't matter how many MCP servers you connect to your MCP host or client. The MCP host and servers will connect over each other through the MCP protocol. The MCP protocol is a transport layer in the middle. Whenever your MCP host or client needs a tool, it's going to connect to the MCP server. The MCP server will then connect\",\n",
              " 'question': 'who is Demis'}"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parallel_chain.invoke('who is Demis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "e6osgdBfRCPN"
      },
      "outputs": [],
      "source": [
        "parser = StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "Y3e2en89QyOC"
      },
      "outputs": [],
      "source": [
        "main_chain = parallel_chain | prompt | llm | parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "Ur7Ph_xlRE-7",
        "outputId": "92122b01-36e9-4de4-85cb-6eb1e893a33d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"The video explains the Model Context Protocol (MCP), a new open-source standard for connecting AI agents to data sources like databases or APIs.  It details the MCP's components (host, client, and server), how they interact, and provides an example using a chat app to illustrate how MCP works with LLMs to retrieve information from various sources.\""
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "main_chain.invoke('What is explained in this video?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
